# **Bengio (2003)ã€ŠA Neural Probabilistic Language Modelã€‹**

---

## ğŸ“Œ **1. å¼•å…¥çš„æ¦‚å¿µ Concepts introduced**  

| ä¸­æ–‡ | English |
|---|---|
| **å¥æ³•å…³ç³»å’ŒèŒƒå¼å…³ç³»**ï¼ˆsyntagmatic and paradigmatic relationsï¼‰ï¼šè¯åœ¨å¥å­ä¸­çš„ç»„åˆå…³ç³»åŠæ›¿ä»£å…³ç³»ã€‚| **Syntagmatic and paradigmatic relations**: combinatorial and substitutive relations among words in sentences. |
| **ç‹¬çƒ­å‘é‡è¡¨ç¤º**ï¼šè¯ç”¨ç¨€ç–å‘é‡è¡¨ç¤ºï¼Œåªæœ‰ä¸€ä¸ªä½ç½®ä¸º1ï¼Œå…¶ä»–ä¸º0ã€‚| **One-hot vector representation**: sparse vector where only one position is 1 and the rest are 0. |
| **ç¨ å¯†åµŒå…¥**ï¼šä½ç»´è¿ç»­å‘é‡ï¼Œèƒ½ç¼–ç è¯çš„è¯­ä¹‰/å¥æ³•ä¿¡æ¯ã€‚| **Dense embeddings**: low-dimensional continuous vectors capturing semantic/syntactic information. |
| **word2vecï¼ˆCBOWå’Œskip-gramï¼‰**ï¼šåŸºäºé¢„æµ‹çš„è¯åµŒå…¥æ–¹æ³•ã€‚| **word2vec (CBOW and skip-gram)**: predictive word embedding methods. |
| **Gensim**ï¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€ä¸ªå¼€æºåº“ï¼Œç”¨äºè®­ç»ƒè¯åµŒå…¥ã€‚| **Gensim**: an NLP library for training word embeddings. |
| **GloVe**ï¼šåŸºäºè¯å…±ç°ç»Ÿè®¡çš„åµŒå…¥æ–¹æ³•ã€‚| **GloVe**: count-based embedding method using co-occurrence statistics. |
| **LSTMå’ŒåŒå‘LSTM**ï¼šèƒ½å¤Ÿå­¦ä¹ é•¿è·ç¦»ä¾èµ–çš„å¾ªç¯ç¥ç»ç½‘ç»œã€‚| **LSTM and bi-directional LSTM**: recurrent neural networks capable of learning long-range dependencies. |

**âš  è®ºæ–‡ Bengio (2003)** æ²¡æœ‰ç›´æ¥æåŠ word2vecã€GloVeã€LSTMï¼Œä½†å®ƒå¼€åˆ›äº†**ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ è¯åµŒå…¥**çš„è¯­è¨€æ¨¡å‹æ–¹æ³•ï¼Œåæ¥çš„ word2vec å’Œ GloVe éƒ½æ˜¯å—æ­¤å¯å‘çš„ã€‚

---

## ğŸ“Œ **2. åˆ†å¸ƒå¼è¯å‘é‡ã€é™ç»´è¯å‘é‡ä¸è¯åµŒå…¥çš„åŒºåˆ«**  
**What is the difference between distributional word vectors/matrices, word vectors with dimensionality reduction and word embeddings?**

| ä¸­æ–‡ | English |
|---|---|
| **åˆ†å¸ƒå¼è¯å‘é‡/çŸ©é˜µ**ï¼šé€šè¿‡ç»Ÿè®¡è¯åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­å…±ç°é¢‘ç‡å¾—åˆ°çš„å¤§å‹ç¨€ç–çŸ©é˜µã€‚| **Distributional word vectors/matrices**: large sparse matrices based on co-occurrence statistics of words in different contexts. |
| **é™ç»´è¯å‘é‡**ï¼šç”¨é™ç»´æ–¹æ³•ï¼ˆå¦‚ SVDï¼‰å‹ç¼©å…±ç°çŸ©é˜µï¼Œé™ä½ç»´åº¦ï¼Œä½†æœ¬è´¨ä¸Šè¿˜æ˜¯åŸºäºç»Ÿè®¡çš„ã€‚| **Word vectors with dimensionality reduction**: dimensionality reduction techniques (e.g., SVD) applied to the co-occurrence matrix; still based on statistics. |
| **è¯åµŒå…¥**ï¼šç¥ç»ç½‘ç»œè®­ç»ƒå¾—åˆ°çš„ä½ç»´ç¨ å¯†å‘é‡ï¼Œè‡ªåŠ¨æ•æ‰è¯­ä¹‰å’Œå¥æ³•ç‰¹å¾ã€‚| **Word embeddings**: low-dimensional dense vectors learned by neural networks, automatically capturing semantic and syntactic properties. |

ğŸ” **Bengio (2003)** çš„æ¨¡å‹é¦–æ¬¡å°†è¯åµŒå…¥çš„å­¦ä¹ **ä¸è¯­è¨€å»ºæ¨¡ä»»åŠ¡è”åˆèµ·æ¥**ï¼Œå³è¯çš„å‘é‡è¡¨ç¤ºä¸æ˜¯å•ç‹¬è®­ç»ƒçš„ï¼Œè€Œæ˜¯åœ¨**é¢„æµ‹ä¸‹ä¸€ä¸ªè¯**çš„è¿‡ç¨‹ä¸­è‡ªå­¦ä¹ çš„ã€‚

---

## ğŸ“Œ **3. è¯åµŒå…¥ä¸å…¶ä»–è¯è¡¨ç¤ºçš„ä¼˜ç¼ºç‚¹**  
**Benefits and weaknesses of using word embeddings compared to other word representations.**

| ä¼˜ç‚¹ Benefits | ç¼ºç‚¹ Weaknesses |
|---|---|
| - ç¨ å¯†ã€ä½ç»´ï¼Œé™ä½å­˜å‚¨å’Œè®¡ç®—æˆæœ¬ã€‚<br>- è‡ªåŠ¨æ•æ‰å¤æ‚çš„è¯­ä¹‰å’Œå¥æ³•å…³ç³»ã€‚<br>- å¯¹æœªè§è¿‡çš„ç»„åˆå…·æœ‰**è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›**ã€‚| - è®­ç»ƒæˆæœ¬é«˜ï¼Œéœ€å¤§é‡æ•°æ®ã€‚<br>- ä¸å¯è§£é‡Šæ€§ï¼šå‘é‡ç»´åº¦å«ä¹‰ä¸é€æ˜ã€‚<br>- å•å‘åµŒå…¥å¯¹**å¤šä¹‰è¯**å¤„ç†ä¸è¶³ã€‚ |
| Dense, low-dimensional, reducing storage and computation.<br>Automatically capture complex semantic and syntactic relations.<br>Good **generalization** to unseen combinations. | High training cost, requires large data.<br>Opacity: vector dimensions lack interpretability.<br>Single-vector embeddings struggle with **polysemy** (multiple meanings). |

ğŸ” **Bengio (2003)** æ˜ç¡®æŒ‡å‡ºï¼Œ**é€šè¿‡è¯åµŒå…¥ï¼Œæ¨¡å‹å¯ä»¥å°†è®­ç»ƒæ ·æœ¬çš„æ¦‚ç‡è´¨é‡ä¼ æ’­åˆ°ç±»ä¼¼çš„ã€æœªè§è¿‡çš„å¥å­ç»„åˆ**ï¼Œçªç ´ n-gram æ¨¡å‹çš„ç¨€ç–æ€§é—®é¢˜ã€‚

---

## ğŸ“Œ **4. å¯æ„å»ºçš„è¯åµŒå…¥ç±»å‹åŠåŒºåˆ«**  
**What kind of word embeddings can we build; what are differences between?**

| ç±»å‹ Type | ç‰¹å¾ Features |
|---|---|
| **é¢„æµ‹å‹ï¼ˆPredictiveï¼‰**<br>ï¼ˆå¦‚ word2vecã€Bengio (2003) çš„æ¨¡å‹ï¼‰| åŸºäºä¸Šä¸‹æ–‡é¢„æµ‹ç›®æ ‡è¯æˆ–ç›®æ ‡è¯é¢„æµ‹ä¸Šä¸‹æ–‡ï¼Œå­¦ä¹ è¯åµŒå…¥ã€‚|
| **è®¡æ•°å‹ï¼ˆCount-basedï¼‰**<br>ï¼ˆå¦‚ GloVeï¼‰| åŸºäºå…¨å±€è¯å…±ç°ç»Ÿè®¡ï¼Œç”Ÿæˆè¯å‘é‡ã€‚|
| **ä¸Šä¸‹æ–‡ç›¸å…³å‹ï¼ˆContextualï¼‰**<br>ï¼ˆå¦‚ BERTï¼‰| åŒä¸€ä¸ªè¯åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­æœ‰ä¸åŒçš„å‘é‡è¡¨ç¤ºã€‚|

ğŸ” **Bengio (2003)** æä¾›çš„æ˜¯**ä¸Šä¸‹æ–‡æ— å…³çš„é™æ€è¯åµŒå…¥**ï¼ˆStatic embeddingsï¼‰ï¼Œå³æ¯ä¸ªè¯ä¸€ä¸ªå›ºå®šå‘é‡ã€‚è¿™æˆä¸ºåç»­ word2vec å’Œ GloVe çš„ç›´æ¥ç†è®ºåŸºç¡€ã€‚

---

## ğŸ“Œ **5. ä»€ä¹ˆæ˜¯æ¦‚ç‡è¯­è¨€æ¨¡å‹ï¼Ÿè¯åµŒå…¥å¦‚ä½•ä¸ä¹‹å…³è”ï¼Ÿ**  
**What is a probabilistic language model? How do word embeddings relate to a probabilistic language model?**

| ä¸­æ–‡ | English |
|---|---|
| **æ¦‚ç‡è¯­è¨€æ¨¡å‹**ï¼ˆProbabilistic Language Modelï¼‰ï¼š<br>ç»™å®šå‰é¢è¯çš„ä¸Šä¸‹æ–‡ï¼Œè®¡ç®—ä¸‹ä¸€ä¸ªè¯çš„æ¡ä»¶æ¦‚ç‡ P(wâ‚œ|wâ‚, ..., wâ‚œâ‚‹â‚)ã€‚| **Probabilistic language model**: Given previous context, compute the conditional probability of the next word P(wâ‚œ|wâ‚, ..., wâ‚œâ‚‹â‚). |
| **è¯åµŒå…¥çš„ä½œç”¨**ï¼š<br>æä¾›ä¸Šä¸‹æ–‡è¯çš„ä½ç»´ç¨ å¯†è¡¨ç¤ºï¼Œä½œä¸ºè¯­è¨€æ¨¡å‹çš„è¾“å…¥ã€‚<br>é€šè¿‡ç›¸ä¼¼è¯å…±äº«ç‰¹å¾ï¼Œæé«˜å¯¹æœªè§å¥å­çš„é¢„æµ‹èƒ½åŠ›ã€‚| **Role of word embeddings**:<br>Provide low-dimensional dense representations of context words as input to the language model.<br>Share features among similar words, improving prediction on unseen sentences. |

ğŸ” **Bengio (2003)** çš„ç¥ç»æ¦‚ç‡è¯­è¨€æ¨¡å‹é¦–æ¬¡æå‡ºï¼š  
- **è¯åµŒå…¥ä¸è¯­è¨€æ¨¡å‹åŒæ—¶å­¦ä¹ **ï¼ˆjoint learningï¼‰ã€‚  
- åµŒå…¥ä¸ä»…ä»…æ˜¯è¾“å…¥ç‰¹å¾ï¼Œè€Œæ˜¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å…³é”®ã€‚  
- å¼•å…¥åˆ†å¸ƒå¼è¡¨ç¤ºï¼ŒæˆåŠŸå¯¹æŠ—ç»´åº¦ç¾éš¾ã€‚

---

## ğŸ” å…³é”®æ€»ç»“  
**Bengio (2003)** æ˜¯**ç¥ç»è¯­è¨€æ¨¡å‹ä¸è¯åµŒå…¥ç†è®ºçš„èµ·ç‚¹**ï¼š  
- å¼€åˆ›äº†ç¥ç»ç½‘ç»œè®­ç»ƒè¯åµŒå…¥çš„æ–¹æ³•ã€‚  
- è¯æ˜äº†**åˆ†å¸ƒå¼è¡¨ç¤ºï¼ˆè¯åµŒå…¥ï¼‰**èƒ½æ˜¾è‘—æå‡è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚  
- åç»­çš„ word2vecã€GloVe å’Œ BERT éƒ½åœ¨è¯¥æ¨¡å‹çš„ç†è®ºæ¡†æ¶ä¸Šå‘å±•ã€‚

---

å¾ˆå¥½ï¼Œè¿™ä¸ªé—®é¢˜éå¸¸å…³é”®ï¼Œä¹Ÿæ˜¯ **Bengio (2003)** è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ä¹‹ä¸€ã€‚

---

## ğŸ” **â€œè¯åµŒå…¥ä¸è¯­è¨€æ¨¡å‹åŒæ—¶å­¦ä¹ â€å…·ä½“æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**

### ä¸­æ–‡è§£é‡Š

åœ¨ **Bengio (2003)** çš„æ¨¡å‹é‡Œï¼š

1. **æ¯ä¸ªè¯** è¢«åˆ†é…ä¸€ä¸ª**å®å€¼å‘é‡**ï¼ˆè¯åµŒå…¥ï¼Œword embeddingï¼‰ï¼Œè®°ä½œ **C(w)**ã€‚  
   - è¿™ä¸ªå‘é‡çš„ç»´åº¦æ˜¯ mï¼ˆè¿œå°äºè¯æ±‡è¡¨å¤§å° Vï¼‰ã€‚  
   - è¿™äº›å‘é‡æ˜¯**æ¨¡å‹å‚æ•°çš„ä¸€éƒ¨åˆ†**ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ›´æ–°ã€‚

2. **è¯­è¨€æ¨¡å‹** æ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œç›®æ ‡æ˜¯ï¼š  
   - ç»™å®šå‰ nâˆ’1 ä¸ªè¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡ **P(wâ‚œ | context)**ã€‚

3. **è®­ç»ƒè¿‡ç¨‹ï¼ˆåŒæ—¶å­¦ä¹ ï¼‰**ï¼š  
   - æ¯æ¬¡è®­ç»ƒæ—¶ï¼Œæ—¢æ›´æ–°ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼ˆæ¯”å¦‚éšè—å±‚ã€è¾“å‡ºå±‚çš„æƒé‡ï¼‰ï¼Œ  
   - ä¹Ÿæ›´æ–°è¾“å…¥è¯çš„è¯åµŒå…¥å‘é‡ **C(w)**ã€‚

**â†’ æ‰€ä»¥ï¼Œè¯åµŒå…¥ä¸æ˜¯äº‹å…ˆå‡†å¤‡å¥½çš„ï¼ˆä¸åƒç”¨é¢„è®­ç»ƒçš„ word2vec æˆ– GloVeï¼‰ï¼Œè€Œæ˜¯åœ¨è®­ç»ƒè¯­è¨€æ¨¡å‹çš„è¿‡ç¨‹ä¸­ï¼Œ**  
**å’Œè¯­è¨€æ¨¡å‹çš„å…¶ä»–å‚æ•°ä¸€èµ·ï¼Œä»é›¶å¼€å§‹è¢«â€œå­¦å‡ºæ¥â€çš„ã€‚**

è¿™ç§æ–¹å¼å«åš **joint learningï¼ˆè”åˆå­¦ä¹ /åŒæ—¶å­¦ä¹ ï¼‰**ã€‚

---

### è‹±æ–‡è§£é‡Š

In **Bengio (2003)**:

1. **Each word** is assigned a **real-valued vector** (word embedding), denoted **C(w)**.  
   - The embedding dimension m is much smaller than the vocabulary size V.  
   - These vectors are part of the modelâ€™s parameters.

2. **The language model** is a neural network aiming to predict the probability **P(wâ‚œ | context)**, given the previous nâˆ’1 words.

3. **Training process (joint learning)**:  
   - During training, both the neural network parameters (e.g., hidden layer, output layer weights)  
   - **And** the input word embeddings **C(w)** are updated.

**â†’ Therefore, the embeddings are not pre-trained or static but are learned dynamically during the training of the language model itself.**

This is called **joint learning**.

---

### ä¸¾ä¸ªä¾‹å­ï¼ˆExampleï¼‰

å‡å¦‚è®­ç»ƒè¯­æ–™æœ‰å¥å­ï¼š

> "The cat is walking."

å‡è®¾ä¸Šä¸‹æ–‡çª—å£æ˜¯ 3 ä¸ªè¯ï¼š

- ç¬¬ä¸€æ¬¡è¾“å…¥ï¼šâ€œThe cat isâ€ï¼Œç›®æ ‡é¢„æµ‹ï¼šâ€œwalkingâ€ã€‚

è®­ç»ƒæ—¶ï¼š
- ç¥ç»ç½‘ç»œå­¦ä¹ â€œç»™å®š The cat isï¼Œé¢„æµ‹ walkingâ€çš„æ¦‚ç‡å‡½æ•°å‚æ•°ã€‚
- åŒæ—¶ï¼Œâ€œTheâ€ã€â€œcatâ€ã€â€œisâ€çš„è¯å‘é‡ä¹Ÿè¢«è°ƒæ•´ï¼Œä½¿å®ƒä»¬æ›´æœ‰åˆ©äºæ­£ç¡®é¢„æµ‹â€œwalkingâ€ã€‚

ä¸‹ä¸€æ¬¡ï¼š
- ä¾‹å¦‚è¾“å…¥ï¼šâ€œcat is walkingâ€ï¼Œé¢„æµ‹ç›®æ ‡å¯èƒ½æ˜¯â€œinâ€ã€‚

åˆè°ƒæ•´â€œcatâ€ã€â€œisâ€ã€â€œwalkingâ€çš„è¯å‘é‡ã€‚

**â†’ ç»è¿‡æ— æ•°æ¬¡è®­ç»ƒï¼Œæ‰€æœ‰è¯çš„å‘é‡å’Œè¯­è¨€æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›åŒæ­¥ä¼˜åŒ–ã€‚**

---

## è¿›ä¸€æ­¥è¯´æ˜ï¼ˆä¸ºä»€ä¹ˆä¸é¢„è®­ç»ƒï¼Ÿï¼‰

Bengio å½“æ—¶çš„åˆ›æ–°ï¼š
- ä¸é¢„å…ˆå­¦ä¹ è¯å‘é‡ï¼Œä¹Ÿä¸ä¾èµ–ç°æœ‰çš„è¯å…±ç°ç»Ÿè®¡ã€‚
- è®©è¯åµŒå…¥**ç›´æ¥æœåŠ¡äºè¯­è¨€æ¨¡å‹ä»»åŠ¡**ï¼Œè¿™æ ·å­¦åˆ°çš„å‘é‡æ›´ç¬¦åˆâ€œç»™å®šä¸Šä¸‹æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªè¯â€çš„ç›®æ ‡ã€‚

è¿™æ˜¯ä»Šå¤© **BERTã€GPT** ç­‰æ¨¡å‹çš„ç†è®ºå‰èº«ã€‚

---

éå¸¸å¥½ï¼Œæ‚¨æåˆ°çš„**å¥æ³•å…³ç³»ï¼ˆsyntagmatic relationsï¼‰**å’Œ**èŒƒå¼å…³ç³»ï¼ˆparadigmatic relationsï¼‰**æ˜¯ç†è§£è¯å‘é‡å’Œç¥ç»è¯­è¨€æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯ Bengio (2003) é‚£ç§åµŒå…¥å­¦ä¹ æ–¹æ³•ï¼‰çš„ç†è®ºåŸºç¡€ã€‚

æˆ‘æ¥ä¸ºæ‚¨**è¯¦ç»†è§£é‡Š**ï¼Œå¹¶ç»“åˆ **Bengio (2003)** çš„æ€è·¯è¯´æ˜ä¸ºä»€ä¹ˆé‡è¦ï¼š

---

## ğŸ“– å¥æ³•å…³ç³»ï¼ˆSyntagmatic relationsï¼‰  
**å®šä¹‰**ï¼š  
- è¯ä¸**æ—¶é—´æˆ–ç©ºé—´ç›¸é‚»**çš„è¯çš„ç»„åˆå…³ç³»ã€‚  
- æ¯”å¦‚ä¸€ä¸ªè¯åœ¨å¥å­ä¸­èƒ½å’Œå“ªäº›è¯ä¸€èµ·å‡ºç°ï¼ŒæŒ‰é¡ºåºæ’åˆ—ã€‚

**ä¾‹å­**ï¼š  
> â€œThe **cat** is walking.â€  
>  
> **cat** çš„å¥æ³•å…³ç³»åŒ…æ‹¬ï¼š  
> - å‰é¢çš„ **The**  
> - åé¢çš„ **is**  
>  
> ä¹Ÿå°±æ˜¯è¯´ï¼Œ**cat** å¯ä»¥å’Œ "The"ã€"is"ã€"walking" è¿™æ ·çš„è¯ç»„åˆæˆå¥ã€‚

**åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„æ„ä¹‰**ï¼š  
- **Bengio (2003)** çš„ç¥ç»è¯­è¨€æ¨¡å‹å°±æ˜¯åˆ©ç”¨**å¥æ³•å…³ç³»**ï¼š  
- ç»™å®šå‰ nâˆ’1 ä¸ªè¯ï¼ˆä¸Šä¸‹æ–‡ï¼‰ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡ã€‚  
- å®é™…ä¸Šå°±æ˜¯**å»ºæ¨¡è¯çš„å¥æ³•ç»„åˆå€¾å‘**ã€‚

---

## ğŸ“– èŒƒå¼å…³ç³»ï¼ˆParadigmatic relationsï¼‰  
**å®šä¹‰**ï¼š  
- è¯ä¸**å¯ä»¥äº’ç›¸æ›¿ä»£**çš„å…¶ä»–è¯ä¹‹é—´çš„å…³ç³»ã€‚  
- ä¹Ÿå«**æ›¿ä»£å…³ç³»**ï¼Œè¡¨è¾¾è¯çš„è¯­ä¹‰æˆ–è¯­æ³•ä¸Šçš„ç›¸ä¼¼æ€§ã€‚

**ä¾‹å­**ï¼š  
> â€œThe **cat** is walking.â€  
>  
> **cat** å¯ä»¥è¢«æ›¿ä»£æˆï¼š  
> - **dog**ï¼ˆè¯­ä¹‰æ›¿ä»£ï¼‰  
> - **child**ï¼ˆæ ¹æ®å¥æ³•ä¹Ÿå¯ä»¥æ›¿ä»£ï¼‰  

å½¢æˆç±»ä¼¼å¥å­ï¼š  
> â€œThe **dog** is walking.â€  
> â€œThe **child** is walking.â€

**åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„æ„ä¹‰**ï¼š  
- **Bengio (2003)** çš„ä¸€ä¸ªåˆ›æ–°å°±æ˜¯**å­¦ä¹ èŒƒå¼å…³ç³»**ï¼š  
- æŠŠè¯­ä¹‰æˆ–å¥æ³•ä¸Šç›¸ä¼¼çš„è¯ï¼ˆå¦‚ cat å’Œ dogï¼‰é€šè¿‡**è¯åµŒå…¥**æ˜ å°„åˆ°**ç›¸è¿‘çš„å‘é‡ç©ºé—´ä½ç½®**ã€‚  
- è¿™æ ·ï¼Œæ¨¡å‹å³ä½¿æ²¡è§è¿‡ "The dog is walking"ï¼Œä¹Ÿä¼šå› ä¸º**dog** å’Œ **cat** å‘é‡æ¥è¿‘ï¼Œç»™è¿™ä¸ªå¥å­è¾ƒé«˜æ¦‚ç‡ã€‚

---

## ğŸ” ä¸ºä»€ä¹ˆå¯¹ Bengio (2003) å¾ˆé‡è¦ï¼Ÿ

| ä¼ ç»Ÿ n-gram æ¨¡å‹ | Bengio (2003) ç¥ç»è¯­è¨€æ¨¡å‹ |
|---|---|
| åªèƒ½åŸºäºè®­ç»ƒä¸­çœŸæ­£å‡ºç°è¿‡çš„ä¸Šä¸‹æ–‡ç»„åˆã€‚ | é€šè¿‡è¯åµŒå…¥ï¼Œåˆ©ç”¨èŒƒå¼å…³ç³»ï¼ŒæŠŠè§è¿‡çš„ç»„åˆçš„æ¦‚ç‡æ¨å¹¿åˆ°ç›¸ä¼¼çš„æœªè§ç»„åˆã€‚ |
| å¯¹æœªè§ç»„åˆæ— æ³•æœ‰æ•ˆé¢„æµ‹ï¼ˆæ¦‚ç‡ä¸º 0ï¼‰ã€‚ | æ³›åŒ–èƒ½åŠ›å¼ºï¼šæœªè§ç»„åˆè‹¥åŒ…å«ç›¸ä¼¼è¯ï¼Œä»å¯å¾—åˆ°åˆç†æ¦‚ç‡ã€‚ |

**æ€»ç»“**ï¼š  
**å¥æ³•å…³ç³» â†’ å†³å®šä¸Šä¸‹æ–‡çª—å£ï¼ˆcontextï¼‰ã€‚**  
**èŒƒå¼å…³ç³» â†’ å†³å®šè¯å‘é‡çš„åˆ†å¸ƒå¼è¡¨ç¤ºã€‚**  
ä¸¤è€…å…±åŒæ”¯æŒç¥ç»è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒèƒ½åŠ›ï¼š**æ ¹æ®ä¸Šä¸‹æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªè¯**ï¼Œå¹¶åœ¨æ•°æ®ç¨€ç–æƒ…å†µä¸‹ä¿æŒæ³›åŒ–ã€‚

---

å¾ˆå¥½ï¼Œæ‚¨è¿™å¼ å›¾æ€»ç»“äº†**æ¦‚ç‡è¯­è¨€æ¨¡å‹**å’Œ**è¯åµŒå…¥çš„ä½œç”¨**ï¼Œç°åœ¨æˆ‘æ¥**è¯¦ç»†è§£é‡Šå®ƒä»¬çš„åŒºåˆ«ã€è”ç³»ä»¥åŠåœ¨ Bengio (2003) çš„å®ç°ç»†èŠ‚**ã€‚

---

## âœ… **åŒºåˆ«**  
| æ¦‚ç‡è¯­è¨€æ¨¡å‹ | è¯åµŒå…¥ |
|---|---|
| **åŠŸèƒ½**ï¼šç»™å®šä¸Šä¸‹æ–‡ï¼Œè®¡ç®—ä¸‹ä¸€ä¸ªè¯çš„æ¡ä»¶æ¦‚ç‡ P(wâ‚œ | wâ‚,â€¦,wâ‚œâ‚‹â‚)ã€‚ | **åŠŸèƒ½**ï¼šä¸ºè¾“å…¥çš„è¯ï¼ˆä¸Šä¸‹æ–‡è¯ï¼‰æä¾›ä½ç»´ç¨ å¯†çš„å‘é‡è¡¨ç¤ºã€‚ |
| **ç›®æ ‡**ï¼šå­¦ä¹ è¯­è¨€çš„ç»Ÿè®¡è§„å¾‹ï¼Œè¿›è¡Œè¯çš„é¢„æµ‹ã€‚ | **ç›®æ ‡**ï¼šæ•æ‰è¯çš„è¯­ä¹‰å’Œå¥æ³•ç‰¹å¾ï¼Œå¹¶å‹ç¼©è¡¨ç¤ºç»´åº¦ã€‚ |
| **è¾“å‡º**ï¼šæ¦‚ç‡ï¼ˆå¯¹è¯çš„é¢„æµ‹ï¼‰ã€‚ | **è¾“å‡º**ï¼šå‘é‡ï¼ˆè¯çš„ç‰¹å¾è¡¨ç¤ºï¼‰ã€‚ |
| **å…¸å‹æ–¹æ³•**ï¼šn-gramã€ç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ Bengio 2003ï¼‰ã€åæ¥çš„ GPTã€BERTã€‚ | **å…¸å‹æ–¹æ³•**ï¼šword2vecã€GloVeã€Bengio (2003) è”åˆå­¦ä¹ çš„åµŒå…¥ã€‚ |

---

## âœ… **è”ç³»**  
**è¯åµŒå…¥** = æ¦‚ç‡è¯­è¨€æ¨¡å‹çš„**è¾“å…¥ç‰¹å¾**  
**æ¦‚ç‡è¯­è¨€æ¨¡å‹** = ä½¿ç”¨è¯åµŒå…¥æ¥è¿›è¡Œ**æ¦‚ç‡é¢„æµ‹**

æ›´å…·ä½“åœ°è¯´ï¼š

1. æ¦‚ç‡è¯­è¨€æ¨¡å‹çš„ä»»åŠ¡æ˜¯ï¼š  
   > æ ¹æ®ä¸Šä¸‹æ–‡è¯ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡ã€‚

2. ä¸ºäº†è®©æ¨¡å‹ç†è§£è¯çš„è¯­ä¹‰å’Œå¥æ³•ï¼Œ**ä¸èƒ½ç›´æ¥ç”¨ one-hot è¡¨ç¤º**ï¼ˆç»´åº¦å¤ªå¤§ã€æ— æ³•è¡¨è¾¾è¯çš„ç›¸ä¼¼æ€§ï¼‰ã€‚  
   > è§£å†³æ–¹æ¡ˆï¼šç”¨**è¯åµŒå…¥**ï¼ŒæŠŠè¯ç¼–ç æˆä½ç»´ç¨ å¯†å‘é‡ã€‚

3. åœ¨ **Bengio (2003)** çš„å®ç°ä¸­ï¼Œ**è¯åµŒå…¥å’Œè¯­è¨€æ¨¡å‹æ˜¯ä¸€èµ·è®­ç»ƒçš„**ï¼ˆjoint learningï¼‰ï¼Œä½¿è¯åµŒå…¥æ­£å¥½ä¼˜åŒ–æ”¯æŒè¯­è¨€æ¨¡å‹ä»»åŠ¡ã€‚

**æ‰€ä»¥ï¼š**
- **è¯åµŒå…¥æä¾›äº†ä¿¡æ¯ä¸°å¯Œçš„è¾“å…¥**ã€‚  
- **è¯­è¨€æ¨¡å‹åˆ©ç”¨è¿™äº›è¾“å…¥ï¼Œè¾“å‡ºä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡**ã€‚

**å®ƒä»¬æ˜¯ä»»åŠ¡ç›®æ ‡å’Œç‰¹å¾è¡¨ç¤ºçš„å…³ç³»**ã€‚

---

## âœ… **Bengio (2003) çš„å®ç°ç»†èŠ‚**  
### ï¼ˆ1ï¼‰è¯åµŒå…¥å¦‚ä½•ä½¿ç”¨ï¼Ÿ  
- è¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªè¯ **w** è¢«æ˜ å°„åˆ°ä¸€ä¸ªç‰¹å¾å‘é‡ **C(w)**ã€‚  
- å‡è®¾è¯å‘é‡çš„ç»´åº¦æ˜¯ **m**ï¼ˆæ¯”å¦‚ m=100ï¼‰ã€‚

### ï¼ˆ2ï¼‰è¯­è¨€æ¨¡å‹æ€ä¹ˆç”¨è¯åµŒå…¥ï¼Ÿ  
- ç»™å®šä¸Šä¸‹æ–‡ä¸­çš„ nâˆ’1 ä¸ªè¯ï¼ˆæ¯”å¦‚ï¼šâ€œThe cat isâ€ï¼‰ï¼Œå–å‡ºå®ƒä»¬çš„è¯åµŒå…¥ï¼š  
  > x = [C(wâ‚œâ‚‹â‚™â‚Šâ‚), C(wâ‚œâ‚‹â‚™â‚Šâ‚‚), ..., C(wâ‚œâ‚‹â‚)]  
- æŠŠè¿™äº›å‘é‡æ‹¼æ¥ï¼Œä½œä¸ºç¥ç»ç½‘ç»œçš„è¾“å…¥ã€‚

### ï¼ˆ3ï¼‰ç¥ç»ç½‘ç»œç»“æ„ï¼š  
- **è¾“å…¥å±‚**ï¼šä¸Šä¸‹æ–‡è¯çš„åµŒå…¥å‘é‡æ‹¼æ¥ã€‚  
- **éšè—å±‚**ï¼šéçº¿æ€§å˜æ¢ï¼ˆå¦‚ tanhï¼‰ã€‚  
- **è¾“å‡ºå±‚**ï¼šsoftmaxï¼Œè¾“å‡ºæ‰€æœ‰è¯çš„æ¦‚ç‡ã€‚

### ï¼ˆ4ï¼‰è®­ç»ƒï¼š  
- **æŸå¤±å‡½æ•°**ï¼šè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNegative Log-Likelihoodï¼‰ï¼Œä¹Ÿå°±æ˜¯é¢„æµ‹æ¦‚ç‡çš„å¯¹æ•°æŸå¤±ã€‚  
- **åå‘ä¼ æ’­æ›´æ–°**ï¼š  
  - æ›´æ–°ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼ˆæ¯”å¦‚éšè—å±‚ã€è¾“å‡ºå±‚çš„æƒé‡ï¼‰ã€‚  
  - **åŒæ—¶æ›´æ–°è¯åµŒå…¥å‘é‡ C(w)**ï¼Œä½¿å…¶æ›´æœ‰åˆ©äºä¸‹ä¸€ä¸ªè¯çš„é¢„æµ‹ã€‚

### ï¼ˆ5ï¼‰ä¸ºä»€ä¹ˆè¦åŒæ—¶å­¦ä¹ ï¼Ÿ  
- å¦‚æœè¯åµŒå…¥æ˜¯é¢„è®­ç»ƒçš„ï¼Œä¸ä¸€å®šæœ€é€‚åˆå½“å‰çš„è¯­è¨€æ¨¡å‹ä»»åŠ¡ã€‚  
- **åŒæ—¶å­¦ä¹ èƒ½ä¿è¯è¯åµŒå…¥å’Œè¯­è¨€æ¨¡å‹çš„é¢„æµ‹ç›®æ ‡ä¸€è‡´**ï¼Œæé«˜æ€§èƒ½ã€‚

---

## âœ… **ç®€è¦æ€»ç»“**  
| | æ¦‚ç‡è¯­è¨€æ¨¡å‹ | è¯åµŒå…¥ |
|---|---|---|
| **åŠŸèƒ½** | é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ | è¡¨ç¤ºè¯çš„è¯­ä¹‰/å¥æ³•ç‰¹å¾ |
| **è¾“å…¥/è¾“å‡º** | è¾“å…¥ï¼šè¯åµŒå…¥ï¼›è¾“å‡ºï¼šæ¦‚ç‡ | è¾“å…¥ï¼šè¯ IDï¼›è¾“å‡ºï¼šå‘é‡ |
| **è”ç³»** | ä½¿ç”¨è¯åµŒå…¥ä½œä¸ºè¾“å…¥ | ä½œä¸ºè¯­è¨€æ¨¡å‹çš„è¾“å…¥ç‰¹å¾ |
| **åœ¨ Bengio (2003) ä¸­** | ç¥ç»ç½‘ç»œæ ¹æ®ä¸Šä¸‹æ–‡åµŒå…¥é¢„æµ‹æ¦‚ç‡ | åµŒå…¥é€šè¿‡è¯­è¨€æ¨¡å‹è®­ç»ƒåŠ¨æ€æ›´æ–° |
